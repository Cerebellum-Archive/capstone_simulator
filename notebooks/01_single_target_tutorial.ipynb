{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Single-Target SPY Prediction\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the fundamentals of quantitative trading strategy development\n",
    "- Learn walk-forward backtesting to avoid look-ahead bias\n",
    "- Implement feature engineering with sector ETFs\n",
    "- Use xarray for standardized results handling\n",
    "- Calculate risk-adjusted performance metrics\n",
    "\n",
    "**Blue Water Macro Corp Educational Framework ¬© 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading\n",
    "\n",
    "First, let's import our libraries and understand what we're trying to accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our custom utilities\n",
    "from utils_simulate import (\n",
    "    simplify_teos, log_returns, p_by_year, \n",
    "    create_results_xarray, plot_xarray_results,\n",
    "    calculate_performance_metrics, get_educational_help\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Welcome to the Blue Water Macro Quantitative Trading Tutorial!\")\n",
    "print(\"üéØ Goal: Predict SPY returns using sector ETF data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Educational Moment: Why Log Returns?\n",
    "\n",
    "Before we dive into data loading, let's understand a fundamental concept in quantitative finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get educational explanation\n",
    "get_educational_help('log_returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Market Data\n",
    "\n",
    "We'll use SPDR sector ETFs as features to predict SPY (S&P 500) returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our universe\n",
    "TARGET_ETF = 'SPY'  # What we want to predict\n",
    "FEATURE_ETFS = [\n",
    "    'XLK',  # Technology\n",
    "    'XLF',  # Financials\n",
    "    'XLV',  # Healthcare\n",
    "    'XLY',  # Consumer Discretionary\n",
    "    'XLP',  # Consumer Staples\n",
    "    'XLE',  # Energy\n",
    "    'XLI',  # Industrials\n",
    "    'XLB',  # Materials\n",
    "    'XLU'   # Utilities\n",
    "]\n",
    "\n",
    "# Download data\n",
    "print(\"üì• Downloading ETF price data...\")\n",
    "all_etfs = [TARGET_ETF] + FEATURE_ETFS\n",
    "data = yf.download(all_etfs, start='2015-01-01', end='2024-12-31')\n",
    "\n",
    "# Use adjusted closing prices\n",
    "prices = data['Adj Close']\n",
    "prices = simplify_teos(prices)  # Normalize timezone\n",
    "\n",
    "print(f\"‚úÖ Downloaded {len(prices)} days of data for {len(all_etfs)} ETFs\")\n",
    "print(f\"üìä Date range: {prices.index.min()} to {prices.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering and Exploration\n",
    "\n",
    "Let's convert prices to log returns and explore the relationships between sector ETFs and SPY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns\n",
    "returns = log_returns(prices).dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X_features = returns[FEATURE_ETFS]\n",
    "y_target = returns[TARGET_ETF]\n",
    "\n",
    "print(f\"üìà Features shape: {X_features.shape}\")\n",
    "print(f\"üéØ Target shape: {y_target.shape}\")\n",
    "\n",
    "# Quick visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot cumulative returns\n",
    "(1 + returns).cumprod().plot(ax=ax1, alpha=0.7)\n",
    "ax1.set_title('Cumulative Returns: SPY vs Sector ETFs')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot rolling correlation with SPY\n",
    "rolling_corr = X_features.rolling(252).corr(y_target).dropna()\n",
    "rolling_corr.plot(ax=ax2, alpha=0.8)\n",
    "ax2.set_title('Rolling 1-Year Correlation with SPY')\n",
    "ax2.set_ylabel('Correlation')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis by Year\n",
    "\n",
    "Let's analyze how the predictive power of each sector changes over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance by year\n",
    "print(\"üîç Analyzing feature importance by year...\")\n",
    "yearly_correlations = p_by_year(X_features, y_target)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(yearly_correlations, annot=True, cmap='RdYlBu_r', center=0, \n",
    "           fmt='.3f', cbar_kws={'label': 'Pearson Correlation'})\n",
    "plt.title('Annual Feature Correlations with SPY Returns')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sector ETF')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most stable predictors\n",
    "mean_abs_corr = yearly_correlations.abs().mean(axis=1).sort_values(ascending=False)\n",
    "print(\"\\nüèÜ Most consistent predictors (by average absolute correlation):\")\n",
    "for etf, corr in mean_abs_corr.head(5).items():\n",
    "    print(f\"  {etf}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Walk-Forward Simulation\n",
    "\n",
    "Now we'll implement the core of quantitative backtesting: walk-forward analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educational explanation\n",
    "get_educational_help('walk_forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from utils_simulate import generate_train_predict_calender\n",
    "\n",
    "def simulate_single_target_strategy(X, y, window_size=252, window_type='expanding'):\n",
    "    \"\"\"\n",
    "    Walk-forward simulation for single-target prediction.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with simulation results\n",
    "    \"\"\"\n",
    "    # Create ML pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', Ridge(alpha=1.0))\n",
    "    ])\n",
    "    \n",
    "    # Generate training/prediction calendar\n",
    "    date_ranges = generate_train_predict_calender(\n",
    "        pd.DataFrame(index=X.index), window_type, window_size\n",
    "    )\n",
    "    \n",
    "    print(f\"üöÄ Starting simulation with {len(date_ranges)} predictions...\")\n",
    "    print(f\"üìÖ Period: {date_ranges[0][0]} to {date_ranges[-1][2]}\")\n",
    "    \n",
    "    results = {\n",
    "        'dates': [],\n",
    "        'predictions': [],\n",
    "        'actuals': [],\n",
    "        'positions': [],\n",
    "        'returns': []\n",
    "    }\n",
    "    \n",
    "    for i, (train_start, train_end, pred_date) in enumerate(date_ranges):\n",
    "        # Training data\n",
    "        X_train = X.loc[train_start:train_end]\n",
    "        y_train = y.loc[train_start:train_end]\n",
    "        \n",
    "        # Prediction data\n",
    "        X_pred = X.loc[[pred_date]]\n",
    "        y_actual = y.loc[pred_date]\n",
    "        \n",
    "        # Fit model and predict\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        prediction = pipeline.predict(X_pred)[0]\n",
    "        \n",
    "        # Simple position sizing: long if prediction > 0, short otherwise\n",
    "        position = 1.0 if prediction > 0 else -1.0\n",
    "        strategy_return = position * y_actual\n",
    "        \n",
    "        # Store results\n",
    "        results['dates'].append(pred_date)\n",
    "        results['predictions'].append(prediction)\n",
    "        results['actuals'].append(y_actual)\n",
    "        results['positions'].append(position)\n",
    "        results['returns'].append(strategy_return)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Progress: {i+1}/{len(date_ranges)} predictions completed\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run simulation\n",
    "simulation_results = simulate_single_target_strategy(X_features, y_target)\n",
    "print(\"‚úÖ Simulation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Results Analysis with xarray\n",
    "\n",
    "Let's use xarray to analyze our results in a standardized way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to xarray Dataset\n",
    "results_df = pd.DataFrame(simulation_results)\n",
    "results_df.set_index('dates', inplace=True)\n",
    "\n",
    "# Create xarray dataset\n",
    "results_xr = create_results_xarray({\n",
    "    'strategy_returns': results_df['returns'],\n",
    "    'spy_returns': results_df['actuals'],\n",
    "    'predictions': results_df['predictions'],\n",
    "    'positions': results_df['positions']\n",
    "}, time_index=results_df.index)\n",
    "\n",
    "print(\"üìä Results stored in xarray Dataset:\")\n",
    "print(results_xr)\n",
    "\n",
    "# Calculate performance metrics\n",
    "strategy_metrics = calculate_performance_metrics(results_xr.strategy_returns)\n",
    "spy_metrics = calculate_performance_metrics(results_xr.spy_returns)\n",
    "\n",
    "print(\"\\nüèÜ Performance Comparison:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Strategy': strategy_metrics,\n",
    "    'SPY Buy-Hold': spy_metrics\n",
    "})\n",
    "print(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Cumulative returns\n",
    "strategy_cumret = (1 + results_xr.strategy_returns).cumprod()\n",
    "spy_cumret = (1 + results_xr.spy_returns).cumprod()\n",
    "\n",
    "strategy_cumret.plot(ax=axes[0,0], label='Strategy', color='blue')\n",
    "spy_cumret.plot(ax=axes[0,0], label='SPY Buy-Hold', color='red')\n",
    "axes[0,0].set_title('Cumulative Returns')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Rolling Sharpe ratio (252-day)\n",
    "rolling_sharpe = (results_xr.strategy_returns.rolling(time=252).mean() / \n",
    "                 results_xr.strategy_returns.rolling(time=252).std() * np.sqrt(252))\n",
    "rolling_sharpe.plot(ax=axes[0,1], color='green')\n",
    "axes[0,1].set_title('Rolling 1-Year Sharpe Ratio')\n",
    "axes[0,1].axhline(y=1.0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Drawdown analysis\n",
    "running_max = strategy_cumret.expanding(dim='time').max()\n",
    "drawdown = (strategy_cumret - running_max) / running_max\n",
    "drawdown.plot(ax=axes[1,0], color='red')\n",
    "axes[1,0].fill_between(drawdown.time, drawdown.values, 0, alpha=0.3, color='red')\n",
    "axes[1,0].set_title('Strategy Drawdown')\n",
    "axes[1,0].set_ylabel('Drawdown %')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction vs actual scatter\n",
    "axes[1,1].scatter(results_xr.predictions, results_xr.spy_returns, alpha=0.5)\n",
    "axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,1].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,1].set_xlabel('Predictions')\n",
    "axes[1,1].set_ylabel('Actual SPY Returns')\n",
    "axes[1,1].set_title('Prediction Accuracy')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate prediction accuracy metrics\n",
    "predictions = results_xr.predictions.values\n",
    "actuals = results_xr.spy_returns.values\n",
    "\n",
    "# Direction accuracy\n",
    "direction_accuracy = np.mean(np.sign(predictions) == np.sign(actuals))\n",
    "correlation = np.corrcoef(predictions, actuals)[0,1]\n",
    "\n",
    "print(f\"\\nüéØ Prediction Metrics:\")\n",
    "print(f\"   Direction Accuracy: {direction_accuracy:.1%}\")\n",
    "print(f\"   Prediction-Actual Correlation: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Student Exercises\n",
    "\n",
    "Now it's your turn to experiment and learn! Try these exercises to deepen your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Position Sizing Improvements\n",
    "\n",
    "Modify the position sizing function to use prediction confidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement confidence-weighted position sizing\n",
    "# Hint: Scale position size by absolute value of prediction\n",
    "\n",
    "def confidence_weighted_positions(predictions, max_leverage=2.0):\n",
    "    \"\"\"\n",
    "    Create position sizes based on prediction confidence.\n",
    "    \n",
    "    Your task:\n",
    "    1. Calculate the absolute value of predictions (confidence)\n",
    "    2. Normalize confidence to [0, max_leverage] range\n",
    "    3. Apply the sign of the original prediction\n",
    "    \n",
    "    Returns:\n",
    "        Array of position sizes\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function\n",
    "test_predictions = np.array([0.01, -0.02, 0.005, -0.03, 0.015])\n",
    "test_positions = confidence_weighted_positions(test_predictions)\n",
    "print(f\"Predictions: {test_predictions}\")\n",
    "print(f\"Positions: {test_positions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Feature Engineering\n",
    "\n",
    "Add momentum indicators to improve predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create momentum features\n",
    "# Ideas:\n",
    "# - 5-day, 20-day moving averages\n",
    "# - RSI (Relative Strength Index)\n",
    "# - Price momentum (current price vs N-day ago)\n",
    "\n",
    "def create_momentum_features(prices, returns):\n",
    "    \"\"\"\n",
    "    Create momentum-based features for prediction.\n",
    "    \n",
    "    Your task:\n",
    "    1. Calculate short-term (5-day) and long-term (20-day) moving averages\n",
    "    2. Create momentum indicators (e.g., current vs past prices)\n",
    "    3. Add volatility measures (rolling standard deviation)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with momentum features\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test with SPY data\n",
    "# momentum_features = create_momentum_features(prices[TARGET_ETF], returns[TARGET_ETF])\n",
    "# print(momentum_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Model Comparison\n",
    "\n",
    "Compare different ML models using xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare Ridge, Random Forest, and Linear Regression\n",
    "# Use xarray to store results from multiple models\n",
    "# Create performance comparison table\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'LinearRegression': LinearRegression()\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1. Run simulation for each model\n",
    "# 2. Store results in xarray with 'model' dimension\n",
    "# 3. Compare performance metrics\n",
    "# 4. Create visualization showing all models\n",
    "\n",
    "print(\"üéØ Model comparison exercise - implement your solution above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Key Takeaways\n",
    "\n",
    "Congratulations! You've completed the single-target simulation tutorial. Here's what you learned:\n",
    "\n",
    "### üéì Concepts Mastered:\n",
    "1. **Log Returns**: Why they're essential for financial modeling\n",
    "2. **Walk-Forward Analysis**: Preventing look-ahead bias in backtests\n",
    "3. **Feature Analysis**: Understanding predictor stability over time\n",
    "4. **xarray Integration**: Standardized handling of financial time series\n",
    "5. **Performance Metrics**: Risk-adjusted return measurement\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "- Complete the exercises above to deepen your understanding\n",
    "- Move to Tutorial 2 for multi-target portfolio strategies\n",
    "- Experiment with different time periods and ETF universes\n",
    "- Try implementing transaction costs and slippage\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- [QuantNet Forums](https://quantnet.com): Connect with other quant students\n",
    "- [Blue Water Macro Blog](https://bluewatermacro.com): Industry insights and research\n",
    "- [xarray Documentation](https://xarray.pydata.org): Master multi-dimensional data analysis\n",
    "\n",
    "**Ready for more advanced techniques? Proceed to Tutorial 2: Multi-Target Portfolio Strategies!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}