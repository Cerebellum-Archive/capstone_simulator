{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Tutorial 1: Single-Target SPY Prediction with Professional Benchmarking\n\n**Learning Objectives:**\n- Understand the fundamentals of quantitative trading strategy development\n- Learn walk-forward backtesting to avoid look-ahead bias\n- Implement feature engineering with sector ETFs\n- **NEW: Professional benchmarking with information ratios and excess returns**\n- **NEW: Generate publication-quality PDF tear sheets**\n- Use xarray for standardized results handling\n- Calculate risk-adjusted performance metrics with extended data coverage (15+ years)\n\n**Blue Water Macro Corp Educational Framework ¬© 2025**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading\n",
    "\n",
    "First, let's import our libraries and understand what we're trying to accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nsys.path.append('../src')\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport yfinance as yf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Import our custom utilities\nfrom utils_simulate import (\n    simplify_teos, log_returns, p_by_year, \n    create_results_xarray, plot_xarray_results,\n    calculate_performance_metrics, get_educational_help\n)\n\n# NEW: Import professional benchmarking and simulation framework\nfrom single_target_simulator import (\n    load_and_prepare_data, Simulate, \n    SingleTargetBenchmarkManager, SingleTargetBenchmarkConfig,\n    sim_stats_single_target, L_func_2, L_func_3, L_func_4\n)\nfrom plotting_utils import create_professional_tear_sheet\n\n# Set plotting style\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\nprint(\"üìö Welcome to the Blue Water Macro Quantitative Trading Tutorial!\")\nprint(\"üéØ Goal: Predict SPY returns using sector ETF data with professional benchmarking\")\nprint(\"üÜï NEW: Extended data coverage (2010-present) and PDF tear sheets!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Educational Moment: Why Log Returns?\n",
    "\n",
    "Before we dive into data loading, let's understand a fundamental concept in quantitative finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get educational explanation\n",
    "get_educational_help('log_returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Market Data\n",
    "\n",
    "We'll use SPDR sector ETFs as features to predict SPY (S&P 500) returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Professional Configuration Setup\nconfig = {\n    \"target_etf\": \"SPY\",\n    \"feature_etfs\": ['XLK', 'XLF', 'XLV', 'XLY', 'XLP', 'XLE', 'XLI', 'XLB', 'XLU'],\n    \"start_date\": \"2010-01-01\",  # Extended coverage: 15+ years\n    \"window_size\": 400,\n    \"window_type\": \"expanding\",\n    \"author\": \"Student\"\n}\n\n# Use professional data loading\nprint(\"üì• Loading data with extended coverage (2010-present)...\")\nX, y = load_and_prepare_data(\n    config[\"feature_etfs\"] + [config[\"target_etf\"]], \n    config[\"target_etf\"], \n    start_date=config[\"start_date\"]\n)\n\nprint(f\"‚úÖ Loaded {len(X)} days of data for {len(config['feature_etfs'])} features\")\nprint(f\"üìä Date range: {X.index.min()} to {X.index.max()}\")\nprint(f\"üéØ Target: {config['target_etf']}\")\nprint(f\"üìà Features: {', '.join(config['feature_etfs'])}\")\n\n# Quick data overview\nprint(f\"\\nüìä Data Summary:\")\nprint(f\"   Features shape: {X.shape}\")\nprint(f\"   Target shape: {y.shape}\")\nprint(f\"   Missing values: {X.isna().sum().sum()} features, {y.isna().sum()} target\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering and Exploration\n",
    "\n",
    "Let's convert prices to log returns and explore the relationships between sector ETFs and SPY:"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Setup Professional Benchmarking Framework\nbenchmark_config = SingleTargetBenchmarkConfig(\n    include_transaction_costs=True,\n    rebalancing_frequency='daily'\n)\n\nbenchmark_manager = SingleTargetBenchmarkManager(\n    target_etf=config[\"target_etf\"],\n    feature_etfs=config[\"feature_etfs\"],\n    config=benchmark_config\n)\n\nprint(\"üéØ Professional Benchmarking Configured!\")\nprint(f\"   Available benchmarks: {list(benchmark_manager.benchmarks.keys())}\")\nprint(f\"   Target ETF: {config['target_etf']}\")\nprint(f\"   Benchmark types:\")\nfor name, benchmark in benchmark_manager.benchmarks.items():\n    print(f\"     - {name}: {benchmark.get_description()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## NEW: Professional Benchmarking Setup\n\nOne of the most important aspects of quantitative finance is comparing your strategy against appropriate benchmarks. Let's set up professional benchmarking:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns\n",
    "returns = log_returns(prices).dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X_features = returns[FEATURE_ETFS]\n",
    "y_target = returns[TARGET_ETF]\n",
    "\n",
    "print(f\"üìà Features shape: {X_features.shape}\")\n",
    "print(f\"üéØ Target shape: {y_target.shape}\")\n",
    "\n",
    "# Quick visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot cumulative returns\n",
    "(1 + returns).cumprod().plot(ax=ax1, alpha=0.7)\n",
    "ax1.set_title('Cumulative Returns: SPY vs Sector ETFs')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot rolling correlation with SPY\n",
    "rolling_corr = X_features.rolling(252).corr(y_target).dropna()\n",
    "rolling_corr.plot(ax=ax2, alpha=0.8)\n",
    "ax2.set_title('Rolling 1-Year Correlation with SPY')\n",
    "ax2.set_ylabel('Correlation')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis by Year\n",
    "\n",
    "Let's analyze how the predictive power of each sector changes over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance by year\n",
    "print(\"üîç Analyzing feature importance by year...\")\n",
    "yearly_correlations = p_by_year(X_features, y_target)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(yearly_correlations, annot=True, cmap='RdYlBu_r', center=0, \n",
    "           fmt='.3f', cbar_kws={'label': 'Pearson Correlation'})\n",
    "plt.title('Annual Feature Correlations with SPY Returns')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sector ETF')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most stable predictors\n",
    "mean_abs_corr = yearly_correlations.abs().mean(axis=1).sort_values(ascending=False)\n",
    "print(\"\\nüèÜ Most consistent predictors (by average absolute correlation):\")\n",
    "for etf, corr in mean_abs_corr.head(5).items():\n",
    "    print(f\"  {etf}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Professional Walk-Forward Simulation with Multiple Position Strategies\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom utils_simulate import EWMTransformer\n\n# Define position sizing strategies to test\nposition_strategies = [\n    ('Binary', L_func_2),      # Simple binary: +1 or -1\n    ('Quartile', L_func_3),    # Quartile-based: 0, 0.5, 1.5, 2.0\n    ('Proportional', L_func_4) # Proportional to prediction strength\n]\n\nprint(\"üöÄ Running professional simulation with multiple strategies...\")\nprint(f\"üìÖ Period: {X.index.min()} to {X.index.max()}\")\nprint(f\"üîÑ Position strategies: {[name for name, _ in position_strategies]}\")\n\n# Run simulations\nregout_list = []\nsweep_tags = []\n\nfor pos_name, pos_func in position_strategies:\n    print(f\"\\nüéØ Running {pos_name} strategy...\")\n    \n    # Create ML pipeline with exponential smoothing\n    pipe = Pipeline([\n        ('ewm', EWMTransformer(halflife=4)),\n        ('ridge', Ridge(alpha=1.0))\n    ])\n    \n    # Run simulation\n    regout = Simulate(\n        X, y, \n        window_size=config[\"window_size\"],\n        window_type=config[\"window_type\"],\n        pipe_steps=pipe,\n        L_func=pos_func,\n        tag=f\"ridge_ewm4_{pos_name.lower()}\"\n    )\n    \n    regout_list.append(regout)\n    sweep_tags.append(f\"ridge_ewm4_{pos_name.lower()}\")\n    \n    print(f\"   ‚úÖ Completed {len(regout)} predictions\")\n\nprint(\"\\n‚úÖ All simulations completed!\")\nprint(f\"üìä Total strategies: {len(regout_list)}\")\nprint(f\"üìà Predictions per strategy: {len(regout_list[0])}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educational explanation\n",
    "get_educational_help('walk_forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Professional Performance Analysis with Benchmarking\nimport time\n\nprint(\"üìä Calculating comprehensive performance statistics with benchmarking...\")\n\n# Define time range for analysis\ntrange = slice(regout_list[0].index[0], regout_list[0].index[-1])\n\n# Calculate professional statistics with benchmarking\nstats_df, enhanced_results = sim_stats_single_target(\n    regout_list, \n    sweep_tags,\n    author=config[\"author\"],\n    trange=trange,\n    target_etf=config[\"target_etf\"],\n    feature_etfs=config[\"feature_etfs\"],\n    benchmark_manager=benchmark_manager,\n    config=config\n)\n\nprint(\"\\nüèÜ PROFESSIONAL PERFORMANCE SUMMARY\")\nprint(\"=\" * 60)\nprint(stats_df.round(4))\n\n# Highlight key metrics\nprint(\"\\nüéØ KEY INSIGHTS:\")\nbest_strategy = stats_df.loc['sharpe'].idxmax()\nbest_sharpe = stats_df.loc['sharpe', best_strategy]\nbest_benchmark = stats_df.loc['best_benchmark', best_strategy]\nexcess_return = stats_df.loc['best_excess_return', best_strategy]\ninfo_ratio = stats_df.loc['best_info_ratio', best_strategy]\n\nprint(f\"   üìà Best Strategy: {best_strategy} (Sharpe: {best_sharpe:.3f})\")\nprint(f\"   üéØ Best Benchmark: {best_benchmark}\")\nprint(f\"   üí∞ Excess Return: {excess_return:.2%} annually\")\nprint(f\"   üìä Information Ratio: {info_ratio:.3f}\")\n\n# Show benchmark comparison for all strategies\nprint(f\"\\nüìä BENCHMARK ANALYSIS:\")\nfor strategy in sweep_tags:\n    benchmark = stats_df.loc['best_benchmark', strategy]\n    excess = stats_df.loc['best_excess_return', strategy] \n    ir = stats_df.loc['best_info_ratio', strategy]\n    print(f\"   {strategy}: vs {benchmark} | Excess: {excess:.2%} | IR: {ir:.3f}\")\n\nprint(f\"\\nüìÖ Analysis Period: {stats_df.loc['start_date', sweep_tags[0]]} to {stats_df.loc['end_date', sweep_tags[0]]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Results Analysis with xarray\n",
    "\n",
    "Let's use xarray to analyze our results in a standardized way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to xarray Dataset\n",
    "results_df = pd.DataFrame(simulation_results)\n",
    "results_df.set_index('dates', inplace=True)\n",
    "\n",
    "# Create xarray dataset\n",
    "results_xr = create_results_xarray({\n",
    "    'strategy_returns': results_df['returns'],\n",
    "    'spy_returns': results_df['actuals'],\n",
    "    'predictions': results_df['predictions'],\n",
    "    'positions': results_df['positions']\n",
    "}, time_index=results_df.index)\n",
    "\n",
    "print(\"üìä Results stored in xarray Dataset:\")\n",
    "print(results_xr)\n",
    "\n",
    "# Calculate performance metrics\n",
    "strategy_metrics = calculate_performance_metrics(results_xr.strategy_returns)\n",
    "spy_metrics = calculate_performance_metrics(results_xr.spy_returns)\n",
    "\n",
    "print(\"\\nüèÜ Performance Comparison:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Strategy': strategy_metrics,\n",
    "    'SPY Buy-Hold': spy_metrics\n",
    "})\n",
    "print(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Generate Professional PDF Tear Sheet\nconfig['run_timestamp'] = time.strftime('%Y%m%d_%H%M%S')\n\nprint(\"üìÑ Generating publication-quality PDF tear sheet...\")\npdf_path = create_professional_tear_sheet(\n    list(enhanced_results.values()),  # Use enhanced results with benchmark data\n    sweep_tags,\n    config\n)\n\nprint(f\"‚úÖ Professional tear sheet generated!\")\nprint(f\"üìÑ PDF: {pdf_path}\")\nprint(f\"üìÅ Location: {os.path.abspath(pdf_path)}\")\n\n# Also create xarray dataset for further analysis\nresults_xr = create_results_xarray(enhanced_results, time_index=enhanced_results[sweep_tags[0]].index)\nprint(f\"\\nüìä Results also available in xarray format:\")\nprint(f\"   Dimensions: {dict(results_xr.dims)}\")\nprint(f\"   Variables: {list(results_xr.data_vars)}\")\n\n# Quick performance visualization\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Extract strategy returns for all strategies\nstrategy_returns = {}\nfor i, tag in enumerate(sweep_tags):\n    strategy_returns[tag] = enhanced_results[tag]['perf_ret']\n\n# 1. Cumulative returns comparison\nfor tag, returns in strategy_returns.items():\n    cumret = (1 + returns).cumprod()\n    cumret.plot(ax=axes[0,0], label=tag.replace('ridge_ewm4_', '').title(), alpha=0.8)\n\naxes[0,0].set_title('Cumulative Strategy Returns')\naxes[0,0].legend()\naxes[0,0].grid(True, alpha=0.3)\n\n# 2. Strategy vs SPY comparison (best strategy)\nbest_returns = enhanced_results[best_strategy]['perf_ret']\nspy_returns = enhanced_results[best_strategy]['actual']\n\n(1 + best_returns).cumprod().plot(ax=axes[0,1], label=f'Best Strategy ({best_strategy})', color='blue')\n(1 + spy_returns).cumprod().plot(ax=axes[0,1], label='SPY Buy-Hold', color='red')\naxes[0,1].set_title('Best Strategy vs SPY')\naxes[0,1].legend()\naxes[0,1].grid(True, alpha=0.3)\n\n# 3. Risk-Return scatter\nreturns_data = []\nvol_data = []\nlabels = []\nfor tag, returns in strategy_returns.items():\n    returns_data.append(returns.mean() * 252)  # Annualized\n    vol_data.append(returns.std() * np.sqrt(252))  # Annualized\n    labels.append(tag.replace('ridge_ewm4_', '').title())\n\naxes[1,0].scatter(vol_data, returns_data, s=100, alpha=0.7)\nfor i, label in enumerate(labels):\n    axes[1,0].annotate(label, (vol_data[i], returns_data[i]), xytext=(5, 5), \n                      textcoords='offset points', fontsize=9)\naxes[1,0].set_xlabel('Annualized Volatility')\naxes[1,0].set_ylabel('Annualized Return')\naxes[1,0].set_title('Risk-Return Profile')\naxes[1,0].grid(True, alpha=0.3)\n\n# 4. Benchmark excess returns\nexcess_returns = []\ninfo_ratios = []\nstrategy_names = []\nfor tag in sweep_tags:\n    excess_returns.append(stats_df.loc['best_excess_return', tag])\n    info_ratios.append(stats_df.loc['best_info_ratio', tag])\n    strategy_names.append(tag.replace('ridge_ewm4_', '').title())\n\nbars = axes[1,1].bar(strategy_names, excess_returns, alpha=0.7)\naxes[1,1].set_title('Excess Returns vs Best Benchmark')\naxes[1,1].set_ylabel('Excess Return (%)')\naxes[1,1].tick_params(axis='x', rotation=45)\naxes[1,1].grid(True, alpha=0.3)\n\n# Add information ratios as text\nfor i, (bar, ir) in enumerate(zip(bars, info_ratios)):\n    height = bar.get_height()\n    axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 0.001,\n                  f'IR: {ir:.2f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nüéâ Tutorial complete! You've learned professional quantitative finance techniques:\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## NEW: Publication-Quality PDF Tear Sheet\n\nLet's generate a professional PDF tear sheet with our benchmark analysis:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Cumulative returns\n",
    "strategy_cumret = (1 + results_xr.strategy_returns).cumprod()\n",
    "spy_cumret = (1 + results_xr.spy_returns).cumprod()\n",
    "\n",
    "strategy_cumret.plot(ax=axes[0,0], label='Strategy', color='blue')\n",
    "spy_cumret.plot(ax=axes[0,0], label='SPY Buy-Hold', color='red')\n",
    "axes[0,0].set_title('Cumulative Returns')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Rolling Sharpe ratio (252-day)\n",
    "rolling_sharpe = (results_xr.strategy_returns.rolling(time=252).mean() / \n",
    "                 results_xr.strategy_returns.rolling(time=252).std() * np.sqrt(252))\n",
    "rolling_sharpe.plot(ax=axes[0,1], color='green')\n",
    "axes[0,1].set_title('Rolling 1-Year Sharpe Ratio')\n",
    "axes[0,1].axhline(y=1.0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Drawdown analysis\n",
    "running_max = strategy_cumret.expanding(dim='time').max()\n",
    "drawdown = (strategy_cumret - running_max) / running_max\n",
    "drawdown.plot(ax=axes[1,0], color='red')\n",
    "axes[1,0].fill_between(drawdown.time, drawdown.values, 0, alpha=0.3, color='red')\n",
    "axes[1,0].set_title('Strategy Drawdown')\n",
    "axes[1,0].set_ylabel('Drawdown %')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction vs actual scatter\n",
    "axes[1,1].scatter(results_xr.predictions, results_xr.spy_returns, alpha=0.5)\n",
    "axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,1].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,1].set_xlabel('Predictions')\n",
    "axes[1,1].set_ylabel('Actual SPY Returns')\n",
    "axes[1,1].set_title('Prediction Accuracy')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate prediction accuracy metrics\n",
    "predictions = results_xr.predictions.values\n",
    "actuals = results_xr.spy_returns.values\n",
    "\n",
    "# Direction accuracy\n",
    "direction_accuracy = np.mean(np.sign(predictions) == np.sign(actuals))\n",
    "correlation = np.corrcoef(predictions, actuals)[0,1]\n",
    "\n",
    "print(f\"\\nüéØ Prediction Metrics:\")\n",
    "print(f\"   Direction Accuracy: {direction_accuracy:.1%}\")\n",
    "print(f\"   Prediction-Actual Correlation: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Student Exercises\n",
    "\n",
    "Now it's your turn to experiment and learn! Try these exercises to deepen your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Position Sizing Improvements\n",
    "\n",
    "Modify the position sizing function to use prediction confidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement confidence-weighted position sizing\n",
    "# Hint: Scale position size by absolute value of prediction\n",
    "\n",
    "def confidence_weighted_positions(predictions, max_leverage=2.0):\n",
    "    \"\"\"\n",
    "    Create position sizes based on prediction confidence.\n",
    "    \n",
    "    Your task:\n",
    "    1. Calculate the absolute value of predictions (confidence)\n",
    "    2. Normalize confidence to [0, max_leverage] range\n",
    "    3. Apply the sign of the original prediction\n",
    "    \n",
    "    Returns:\n",
    "        Array of position sizes\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test your function\n",
    "test_predictions = np.array([0.01, -0.02, 0.005, -0.03, 0.015])\n",
    "test_positions = confidence_weighted_positions(test_predictions)\n",
    "print(f\"Predictions: {test_predictions}\")\n",
    "print(f\"Positions: {test_positions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 6: Key Takeaways\n\nCongratulations! You've completed the enhanced single-target simulation tutorial with professional benchmarking. Here's what you learned:\n\n### üéì Concepts Mastered:\n1. **Extended Data Coverage**: Working with 15+ years of market data (2010-present)\n2. **Professional Configuration**: Structured parameter management for reproducible research\n3. **Walk-Forward Analysis**: Preventing look-ahead bias in backtests\n4. **Professional Benchmarking**: Information ratios, excess returns, and best benchmark selection\n5. **Multiple Position Strategies**: Binary, quartile, and proportional position sizing\n6. **Publication-Quality Reports**: PDF tear sheets with comprehensive performance analysis\n7. **xarray Integration**: Standardized handling of financial time series\n\n### üÜï NEW Professional Features:\n- ‚úÖ **Benchmark Framework**: Buy-and-hold, zero-return, and custom benchmarks\n- ‚úÖ **Information Ratios**: Risk-adjusted excess return measurement\n- ‚úÖ **PDF Tear Sheets**: Publication-quality performance reports\n- ‚úÖ **Extended Data**: 15+ years of robust backtesting data\n- ‚úÖ **Configuration Management**: Professional parameter handling\n\n### üìä Key Metrics You Now Understand:\n- **Sharpe Ratio**: Risk-adjusted returns (return/volatility)\n- **Information Ratio**: Excess return per unit of tracking error\n- **Excess Return**: Strategy outperformance vs benchmark\n- **Maximum Drawdown**: Largest peak-to-trough decline\n- **Best Benchmark**: Optimal comparison for each strategy\n\n### üöÄ Next Steps:\n- Complete the updated exercises below to practice these concepts\n- Move to Tutorial 2 for multi-target portfolio strategies with advanced benchmarking\n- Experiment with different time periods and ETF universes\n- Try implementing custom benchmarks and risk metrics\n\n### üí° Professional Applications:\n- **Portfolio Management**: These techniques are used by quantitative portfolio managers\n- **Risk Management**: Benchmark analysis is critical for institutional risk control  \n- **Performance Attribution**: Understanding sources of returns vs market factors\n- **Client Reporting**: PDF tear sheets are standard in professional asset management\n\n### üìö Additional Resources:\n- [QuantNet Forums](https://quantnet.com): Connect with other quant students\n- [Blue Water Macro Blog](https://bluewatermacro.com): Industry insights and research\n- [xarray Documentation](https://xarray.pydata.org): Master multi-dimensional data analysis\n\n**Ready for advanced multi-asset portfolio strategies? Proceed to Tutorial 2!**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create momentum features\n",
    "# Ideas:\n",
    "# - 5-day, 20-day moving averages\n",
    "# - RSI (Relative Strength Index)\n",
    "# - Price momentum (current price vs N-day ago)\n",
    "\n",
    "def create_momentum_features(prices, returns):\n",
    "    \"\"\"\n",
    "    Create momentum-based features for prediction.\n",
    "    \n",
    "    Your task:\n",
    "    1. Calculate short-term (5-day) and long-term (20-day) moving averages\n",
    "    2. Create momentum indicators (e.g., current vs past prices)\n",
    "    3. Add volatility measures (rolling standard deviation)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with momentum features\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test with SPY data\n",
    "# momentum_features = create_momentum_features(prices[TARGET_ETF], returns[TARGET_ETF])\n",
    "# print(momentum_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Model Comparison\n",
    "\n",
    "Compare different ML models using xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare Ridge, Random Forest, and Linear Regression\n",
    "# Use xarray to store results from multiple models\n",
    "# Create performance comparison table\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'LinearRegression': LinearRegression()\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1. Run simulation for each model\n",
    "# 2. Store results in xarray with 'model' dimension\n",
    "# 3. Compare performance metrics\n",
    "# 4. Create visualization showing all models\n",
    "\n",
    "print(\"üéØ Model comparison exercise - implement your solution above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Key Takeaways\n",
    "\n",
    "Congratulations! You've completed the single-target simulation tutorial. Here's what you learned:\n",
    "\n",
    "### üéì Concepts Mastered:\n",
    "1. **Log Returns**: Why they're essential for financial modeling\n",
    "2. **Walk-Forward Analysis**: Preventing look-ahead bias in backtests\n",
    "3. **Feature Analysis**: Understanding predictor stability over time\n",
    "4. **xarray Integration**: Standardized handling of financial time series\n",
    "5. **Performance Metrics**: Risk-adjusted return measurement\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "- Complete the exercises above to deepen your understanding\n",
    "- Move to Tutorial 2 for multi-target portfolio strategies\n",
    "- Experiment with different time periods and ETF universes\n",
    "- Try implementing transaction costs and slippage\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- [QuantNet Forums](https://quantnet.com): Connect with other quant students\n",
    "- [Blue Water Macro Blog](https://bluewatermacro.com): Industry insights and research\n",
    "- [xarray Documentation](https://xarray.pydata.org): Master multi-dimensional data analysis\n",
    "\n",
    "**Ready for more advanced techniques? Proceed to Tutorial 2: Multi-Target Portfolio Strategies!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}